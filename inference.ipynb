{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "This notebook generates the labels for the unlabelled \"test_dataset\" using the pretrained model that was trained in \"training.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation\n",
    "Importing libraries and defining the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, datasets\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import torchvision.transforms.functional as IFU\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model\n",
    "Defining the model architecture and loading the pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating a CNN-based image classifier.\n",
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_layer_1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32)\n",
    "        )\n",
    "        self.conv_layer_2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "        self.conv_layer_3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(512)\n",
    "        )\n",
    "\n",
    "        self.conv_layer_4 = nn.Sequential(\n",
    "          nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "          nn.ReLU(),\n",
    "          nn.BatchNorm2d(512))\n",
    "        \n",
    "        self.conv_layer_5 = nn.Sequential(\n",
    "          nn.Conv2d(512, 256, kernel_size=3, padding=1),\n",
    "          nn.ReLU(),\n",
    "          nn.BatchNorm2d(256))\n",
    "\n",
    "        self.max_pool = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.avg_pool = nn.AvgPool2d(2)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "          nn.Flatten(),\n",
    "          nn.Linear(in_features=256*3*3, out_features=128),\n",
    "          nn.ReLU(),\n",
    "          nn.Dropout(0.1),\n",
    "          nn.Linear(in_features=128, out_features=8),)\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.conv_layer_1(x)\n",
    "        x = self.max_pool(self.conv_layer_2(x))\n",
    "        x = self.avg_pool(self.conv_layer_3(x))\n",
    "        x = self.avg_pool(self.conv_layer_4(x))\n",
    "        x = self.max_pool(self.conv_layer_4(x))\n",
    "        x = self.max_pool(self.conv_layer_4(x))\n",
    "        x = self.max_pool(self.conv_layer_4(x))\n",
    "        x = self.conv_layer_5(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "# Instantiate an object.\n",
    "model = ImageClassifier().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = True #### SET TO TRUE IF YOU HAVE A PRESAVED CHECKPOINT\n",
    "if load:\n",
    "    checkpoint = torch.load(\"final_model_data.pt\")\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    results = checkpoint['results']\n",
    "    done_epochs = checkpoint['epoch']\n",
    "else:\n",
    "    results = None\n",
    "    done_epochs = 0\n",
    "\n",
    "done_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Pass for a Single Image\n",
    "Demonstrating the forward pass and inference by the model for one single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Printing Model Summary\n",
    "\n",
    "IMAGE_WIDTH = 200\n",
    "IMAGE_HEIGHT = 200\n",
    "# Install torchinfo if it's not available, import it if it is\n",
    "try:\n",
    "    import torchinfo\n",
    "except:\n",
    "    !pip install torchinfo\n",
    "    import torchinfo\n",
    "\n",
    "from torchinfo import summary\n",
    "# do a test pass through of an example input size\n",
    "summary(model, input_size=[1, 1, IMAGE_WIDTH ,IMAGE_HEIGHT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformation for images\n",
    "IMAGE_SIZE = (200, 200)\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to get image from filename\n",
    "def get_image(filename, transform = None):\n",
    "    image = Image.open(filename)\n",
    "    if transform:\n",
    "        image = transform(image)\n",
    "\n",
    "    image = IFU.adjust_contrast(image, 1.8)\n",
    "    return image\n",
    "\n",
    "img_list = [] # List of paths to images\n",
    "for i in range(2000):\n",
    "    img_list.append(os.path.join(\"test_dataset\", str(i+1)+\".jpg\"))\n",
    "\n",
    "img = get_image(img_list[1491], data_transform) ## Selecting one random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img.permute(1,2,0), cmap=\"Greys_r\") ## Displaying the image\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model prediction for the single image\n",
    "\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    pred = model(img.unsqueeze(1).to(device))\n",
    "\n",
    "print(f\"Output logits:\\n{pred}\\n\")\n",
    "print(f\"Output prediction probabilities:\\n{torch.softmax(pred, dim=1)}\\n\")\n",
    "print(f\"Output prediction label:\\n{torch.argmax(torch.softmax(pred, dim=1), dim=1).item()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference for all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generating prediction for all images in the test_dataset\n",
    "\n",
    "predictions = []\n",
    "for i in range(2000):\n",
    "    image_path = img_list[i]\n",
    "    img = get_image(image_path, data_transform)\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        pred = model(img.unsqueeze(1).to(device))\n",
    "\n",
    "    label = torch.argmax(torch.softmax(pred, dim=1), dim=1)\n",
    "    predictions.append(label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mapping prediction labels with their classes\n",
    "\n",
    "label_to_int_map = {\n",
    "    'bright dune': 0,\n",
    "    'dark dune': 1,\n",
    "    'spider': 2,\n",
    "    'impact ejecta': 3,\n",
    "    'slope streak': 4,\n",
    "    'swiss cheese': 5,\n",
    "    'crater': 6,\n",
    "    'other': 7\n",
    "}\n",
    "\n",
    "int_to_label_map = {v:k for k, v in label_to_int_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building the final dataframe from the predictions and exporting it as a CSV file\n",
    "\n",
    "img_names_series = pd.Series([str(i) + \".jpg\" for i in range(1, 2001)])\n",
    "pred_labels_series = pd.Series(predictions)\n",
    "pred_label_names = pred_labels_series.replace(int_to_label_map)\n",
    "\n",
    "out_df = pd.DataFrame({\n",
    "    \"File Name\":img_names_series,\n",
    "    \"Class\":pred_label_names\n",
    "})\n",
    "\n",
    "out_df.to_csv(\"the_crue_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
